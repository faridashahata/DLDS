{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136b5641-594a-4e0e-a07b-40931303890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:22:01.874836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 15:22:06.489775: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-20 15:22:15.538932: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-20 15:22:15.539228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-20 15:22:15.539248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceae02db-4c0e-405a-86c1-7796ebaabbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:24:55.455012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 15:24:56.091040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 15:24:56.092873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2ecc22-2392-4621-aba6-9efd84dbd8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
      "_openmp_mutex             4.5                       2_gnu    conda-forge\n",
      "absl-py                   1.4.0                    pypi_0    pypi\n",
      "aiohttp                   3.8.4                    pypi_0    pypi\n",
      "aiohttp-cors              0.7.0                    pypi_0    pypi\n",
      "aiorwlock                 1.3.0                    pypi_0    pypi\n",
      "aiosignal                 1.3.1              pyhd8ed1ab_0    conda-forge\n",
      "ansiwrap                  0.8.4                    pypi_0    pypi\n",
      "anyio                     3.6.2              pyhd8ed1ab_0    conda-forge\n",
      "apache-beam               2.46.0                   pypi_0    pypi\n",
      "argon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge\n",
      "argon2-cffi-bindings      21.2.0           py37h540881e_2    conda-forge\n",
      "astunparse                1.6.3                    pypi_0    pypi\n",
      "async-timeout             4.0.2              pyhd8ed1ab_0    conda-forge\n",
      "asynctest                 0.13.0                     py_0    conda-forge\n",
      "attrs                     22.2.0             pyh71513ae_0    conda-forge\n",
      "babel                     2.12.1                   pypi_0    pypi\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\n",
      "backoff                   2.2.1                    pypi_0    pypi\n",
      "backports                 1.0                pyhd8ed1ab_3    conda-forge\n",
      "backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\n",
      "beatrix-jupyterlab        2023.324.164149          pypi_0    pypi\n",
      "beautifulsoup4            4.12.0             pyha770c72_0    conda-forge\n",
      "bleach                    6.0.0              pyhd8ed1ab_0    conda-forge\n",
      "blessed                   1.20.0                   pypi_0    pypi\n",
      "brotlipy                  0.7.0           py37h27cfd23_1003  \n",
      "c-ares                    1.18.1               h7f98852_0    conda-forge\n",
      "ca-certificates           2022.12.7            ha878542_0    conda-forge\n",
      "cachetools                4.2.4                    pypi_0    pypi\n",
      "certifi                   2022.12.7          pyhd8ed1ab_0    conda-forge\n",
      "cffi                      1.15.1           py37h43b0acd_1    conda-forge\n",
      "charset-normalizer        2.1.1              pyhd8ed1ab_0    conda-forge\n",
      "click                     8.1.3                    pypi_0    pypi\n",
      "cloud-tpu-client          0.10                     pypi_0    pypi\n",
      "cloud-tpu-profiler        2.4.0                    pypi_0    pypi\n",
      "cloudpickle               2.2.1                    pypi_0    pypi\n",
      "colorama                  0.4.6                    pypi_0    pypi\n",
      "colorful                  0.5.5                    pypi_0    pypi\n",
      "conda                     22.9.0           py37h89c1867_1    conda-forge\n",
      "conda-content-trust       0.1.1              pyhd3eb1b0_0  \n",
      "conda-package-handling    2.0.2              pyh38be061_0    conda-forge\n",
      "conda-package-streaming   0.7.0              pyhd8ed1ab_1    conda-forge\n",
      "crcmod                    1.7                      pypi_0    pypi\n",
      "cryptography              38.0.2           py37h5994e8b_1    conda-forge\n",
      "cycler                    0.11.0                   pypi_0    pypi\n",
      "cython                    0.29.33                  pypi_0    pypi\n",
      "db-dtypes                 1.0.5                    pypi_0    pypi\n",
      "debugpy                   1.6.6                    pypi_0    pypi\n",
      "decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\n",
      "defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\n",
      "deprecated                1.2.13                   pypi_0    pypi\n",
      "dill                      0.3.1.1                  pypi_0    pypi\n",
      "distlib                   0.3.6                    pypi_0    pypi\n",
      "dlenv-tf-2-10-gpu         1.0.20230327     py37hca0c132_0    file:///tmp/conda\n",
      "dm-tree                   0.1.8                    pypi_0    pypi\n",
      "docker                    6.0.1                    pypi_0    pypi\n",
      "docopt                    0.6.2                    pypi_0    pypi\n",
      "entrypoints               0.4                pyhd8ed1ab_0    conda-forge\n",
      "etils                     0.9.0                    pypi_0    pypi\n",
      "explainable-ai-sdk        1.3.3                    pypi_0    pypi\n",
      "fastapi                   0.95.0                   pypi_0    pypi\n",
      "fastavro                  1.7.3                    pypi_0    pypi\n",
      "fasteners                 0.18                     pypi_0    pypi\n",
      "filelock                  3.10.6                   pypi_0    pypi\n",
      "flatbuffers               23.3.3                   pypi_0    pypi\n",
      "flit-core                 3.8.0              pyhd8ed1ab_0    conda-forge\n",
      "fonttools                 4.38.0                   pypi_0    pypi\n",
      "frozenlist                1.3.3                    pypi_0    pypi\n",
      "fsspec                    2023.1.0                 pypi_0    pypi\n",
      "gast                      0.4.0                    pypi_0    pypi\n",
      "gcsfs                     2023.1.0                 pypi_0    pypi\n",
      "gitdb                     4.0.10                   pypi_0    pypi\n",
      "gitpython                 3.1.31                   pypi_0    pypi\n",
      "google-api-core           1.34.0                   pypi_0    pypi\n",
      "google-api-core-grpc      2.10.1               hd8ed1ab_0    conda-forge\n",
      "google-api-python-client  1.8.0                    pypi_0    pypi\n",
      "google-apitools           0.5.31                   pypi_0    pypi\n",
      "google-auth               2.16.3             pyh1a96a4e_0    conda-forge\n",
      "google-auth-httplib2      0.1.0                    pypi_0    pypi\n",
      "google-auth-oauthlib      0.4.6                    pypi_0    pypi\n",
      "google-cloud-aiplatform   1.23.0                   pypi_0    pypi\n",
      "google-cloud-artifact-registry 1.8.0                    pypi_0    pypi\n",
      "google-cloud-bigquery     3.7.0                    pypi_0    pypi\n",
      "google-cloud-bigquery-storage 2.16.2                   pypi_0    pypi\n",
      "google-cloud-bigtable     1.7.3                    pypi_0    pypi\n",
      "google-cloud-core         2.3.2              pyhd8ed1ab_0    conda-forge\n",
      "google-cloud-datastore    1.15.5             pyhd8ed1ab_0    conda-forge\n",
      "google-cloud-dlp          3.12.0                   pypi_0    pypi\n",
      "google-cloud-language     1.3.2                    pypi_0    pypi\n",
      "google-cloud-monitoring   2.14.1                   pypi_0    pypi\n",
      "google-cloud-pubsub       2.15.2                   pypi_0    pypi\n",
      "google-cloud-pubsublite   1.7.0                    pypi_0    pypi\n",
      "google-cloud-recommendations-ai 0.7.1                    pypi_0    pypi\n",
      "google-cloud-resource-manager 1.9.0                    pypi_0    pypi\n",
      "google-cloud-spanner      3.29.0                   pypi_0    pypi\n",
      "google-cloud-storage      2.7.0                    pypi_0    pypi\n",
      "google-cloud-videointelligence 1.16.3                   pypi_0    pypi\n",
      "google-cloud-vision       3.4.0                    pypi_0    pypi\n",
      "google-crc32c             1.5.0                    pypi_0    pypi\n",
      "google-pasta              0.2.0                    pypi_0    pypi\n",
      "google-resumable-media    2.4.1                    pypi_0    pypi\n",
      "googleapis-common-protos  1.59.0                   pypi_0    pypi\n",
      "gpustat                   1.0.0                    pypi_0    pypi\n",
      "greenlet                  2.0.2                    pypi_0    pypi\n",
      "grpc-cpp                  1.48.1               hc2bec63_1    conda-forge\n",
      "grpc-google-iam-v1        0.12.6                   pypi_0    pypi\n",
      "grpcio                    1.51.3                   pypi_0    pypi\n",
      "grpcio-status             1.48.2                   pypi_0    pypi\n",
      "gviz-api                  1.10.0                   pypi_0    pypi\n",
      "gymnasium                 0.26.3                   pypi_0    pypi\n",
      "gymnasium-notices         0.0.1                    pypi_0    pypi\n",
      "h11                       0.14.0                   pypi_0    pypi\n",
      "h5py                      3.8.0                    pypi_0    pypi\n",
      "hdfs                      2.7.0                    pypi_0    pypi\n",
      "htmlmin                   0.1.12                   pypi_0    pypi\n",
      "httplib2                  0.21.0                   pypi_0    pypi\n",
      "icu                       70.1                 h27087fc_0    conda-forge\n",
      "idna                      3.4                pyhd8ed1ab_0    conda-forge\n",
      "imagehash                 4.3.1                    pypi_0    pypi\n",
      "imageio                   2.26.1                   pypi_0    pypi\n",
      "importlib-metadata        6.0.1                    pypi_0    pypi\n",
      "importlib_resources       5.12.0             pyhd8ed1ab_0    conda-forge\n",
      "ipykernel                 6.16.2             pyh210e3f2_0    conda-forge\n",
      "ipython                   7.34.0                   pypi_0    pypi\n",
      "ipython-genutils          0.2.0                    pypi_0    pypi\n",
      "ipython-sql               0.5.0                    pypi_0    pypi\n",
      "ipython_genutils          0.2.0                      py_1    conda-forge\n",
      "ipywidgets                8.0.5                    pypi_0    pypi\n",
      "jaraco-classes            3.2.3                    pypi_0    pypi\n",
      "jedi                      0.18.2             pyhd8ed1ab_0    conda-forge\n",
      "jeepney                   0.8.0                    pypi_0    pypi\n",
      "jinja2                    3.1.2              pyhd8ed1ab_1    conda-forge\n",
      "joblib                    1.2.0                    pypi_0    pypi\n",
      "json5                     0.9.11                   pypi_0    pypi\n",
      "jsonschema                4.17.3             pyhd8ed1ab_0    conda-forge\n",
      "jupyter-core              4.12.0                   pypi_0    pypi\n",
      "jupyter-http-over-ws      0.0.8                    pypi_0    pypi\n",
      "jupyter-server            1.23.6                   pypi_0    pypi\n",
      "jupyter-server-mathjax    0.2.6                    pypi_0    pypi\n",
      "jupyter-server-proxy      3.2.2                    pypi_0    pypi\n",
      "jupyter_client            7.4.9              pyhd8ed1ab_0    conda-forge\n",
      "jupyter_core              4.11.1           py37h89c1867_0    conda-forge\n",
      "jupyter_server            1.23.4             pyhd8ed1ab_0    conda-forge\n",
      "jupyterlab                3.4.8                    pypi_0    pypi\n",
      "jupyterlab-git            0.41.0                   pypi_0    pypi\n",
      "jupyterlab-server         2.21.0                   pypi_0    pypi\n",
      "jupyterlab-widgets        3.0.6                    pypi_0    pypi\n",
      "jupyterlab_pygments       0.2.2              pyhd8ed1ab_0    conda-forge\n",
      "jupytext                  1.14.5                   pypi_0    pypi\n",
      "keras                     2.10.0                   pypi_0    pypi\n",
      "keras-preprocessing       1.1.2                    pypi_0    pypi\n",
      "keras-tuner               1.3.0                    pypi_0    pypi\n",
      "keyring                   23.13.1                  pypi_0    pypi\n",
      "keyrings-google-artifactregistry-auth 1.1.2                    pypi_0    pypi\n",
      "kiwisolver                1.4.4                    pypi_0    pypi\n",
      "kt-legacy                 1.0.4                    pypi_0    pypi\n",
      "kubernetes                26.1.0                   pypi_0    pypi\n",
      "ld_impl_linux-64          2.40                 h41732ed_0    conda-forge\n",
      "libabseil                 20220623.0      cxx17_h05df665_6    conda-forge\n",
      "libclang                  16.0.0                   pypi_0    pypi\n",
      "libffi                    3.4.2                h7f98852_5    conda-forge\n",
      "libgcc-ng                 12.2.0              h65d4601_19    conda-forge\n",
      "libgomp                   12.2.0              h65d4601_19    conda-forge\n",
      "libnsl                    2.0.0                h7f98852_0    conda-forge\n",
      "libprotobuf               3.20.1               h6239696_4    conda-forge\n",
      "libsodium                 1.0.18               h36c2ea0_1    conda-forge\n",
      "libsqlite                 3.40.0               h753d276_0    conda-forge\n",
      "libstdcxx-ng              12.2.0              h46fd767_19    conda-forge\n",
      "libuv                     1.44.2               h166bdaf_0    conda-forge\n",
      "libzlib                   1.2.13               h166bdaf_4    conda-forge\n",
      "llvmlite                  0.39.1                   pypi_0    pypi\n",
      "lz4                       4.3.2                    pypi_0    pypi\n",
      "markdown                  3.4.3                    pypi_0    pypi\n",
      "markdown-it-py            2.2.0                    pypi_0    pypi\n",
      "markupsafe                2.0.1                    pypi_0    pypi\n",
      "matplotlib                3.5.3                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge\n",
      "mdit-py-plugins           0.3.5                    pypi_0    pypi\n",
      "mdurl                     0.1.2                    pypi_0    pypi\n",
      "mistune                   2.0.5              pyhd8ed1ab_0    conda-forge\n",
      "more-itertools            9.1.0                    pypi_0    pypi\n",
      "msgpack                   1.0.5                    pypi_0    pypi\n",
      "multidict                 6.0.4                    pypi_0    pypi\n",
      "multimethod               1.9.1                    pypi_0    pypi\n",
      "nb_conda                  2.2.1                    unix_6    conda-forge\n",
      "nb_conda_kernels          2.3.1            py37h89c1867_1    conda-forge\n",
      "nbclassic                 0.5.3              pyhb4ecaf3_3    conda-forge\n",
      "nbclient                  0.7.2                    pypi_0    pypi\n",
      "nbconvert                 7.2.10                   pypi_0    pypi\n",
      "nbconvert-core            7.2.9              pyhd8ed1ab_0    conda-forge\n",
      "nbconvert-pandoc          7.2.9              pyhd8ed1ab_0    conda-forge\n",
      "nbdime                    3.1.1                    pypi_0    pypi\n",
      "nbformat                  5.8.0              pyhd8ed1ab_0    conda-forge\n",
      "ncurses                   6.3                  h7f8727e_2  \n",
      "nest-asyncio              1.5.6              pyhd8ed1ab_0    conda-forge\n",
      "networkx                  2.6.3                    pypi_0    pypi\n",
      "nodejs                    18.15.0              h8d033a5_0    conda-forge\n",
      "notebook                  6.5.3              pyha770c72_0    conda-forge\n",
      "notebook-executor         0.2                      pypi_0    pypi\n",
      "notebook-shim             0.2.2              pyhd8ed1ab_0    conda-forge\n",
      "numba                     0.56.4                   pypi_0    pypi\n",
      "numpy                     1.21.6                   pypi_0    pypi\n",
      "nvidia-ml-py              11.495.46                pypi_0    pypi\n",
      "oauth2client              4.1.3                    pypi_0    pypi\n",
      "oauthlib                  3.2.2                    pypi_0    pypi\n",
      "objsize                   0.6.1                    pypi_0    pypi\n",
      "opencensus                0.11.2                   pypi_0    pypi\n",
      "opencensus-context        0.1.3                    pypi_0    pypi\n",
      "openssl                   3.1.0                h0b41bf4_0    conda-forge\n",
      "opentelemetry-api         1.17.0                   pypi_0    pypi\n",
      "opentelemetry-exporter-otlp 1.17.0                   pypi_0    pypi\n",
      "opentelemetry-exporter-otlp-proto-grpc 1.17.0                   pypi_0    pypi\n",
      "opentelemetry-exporter-otlp-proto-http 1.17.0                   pypi_0    pypi\n",
      "opentelemetry-proto       1.17.0                   pypi_0    pypi\n",
      "opentelemetry-sdk         1.17.0                   pypi_0    pypi\n",
      "opentelemetry-semantic-conventions 0.38b0                   pypi_0    pypi\n",
      "opt-einsum                3.3.0                    pypi_0    pypi\n",
      "orjson                    3.8.8                    pypi_0    pypi\n",
      "overrides                 6.5.0                    pypi_0    pypi\n",
      "packaging                 21.3                     pypi_0    pypi\n",
      "pandas                    1.3.5                    pypi_0    pypi\n",
      "pandas-profiling          3.6.6                    pypi_0    pypi\n",
      "pandoc                    3.1.1                h32600fe_0    conda-forge\n",
      "pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\n",
      "papermill                 2.4.0                    pypi_0    pypi\n",
      "parso                     0.8.3              pyhd8ed1ab_0    conda-forge\n",
      "patsy                     0.5.3                    pypi_0    pypi\n",
      "pexpect                   4.8.0              pyh1a96a4e_2    conda-forge\n",
      "phik                      0.12.3                   pypi_0    pypi\n",
      "pickleshare               0.7.5                   py_1003    conda-forge\n",
      "pillow                    9.4.0                    pypi_0    pypi\n",
      "pip                       23.0.1             pyhd8ed1ab_0    conda-forge\n",
      "pkgutil-resolve-name      1.3.10             pyhd8ed1ab_0    conda-forge\n",
      "platformdirs              3.2.0                    pypi_0    pypi\n",
      "plotly                    5.13.1                   pypi_0    pypi\n",
      "pluggy                    1.0.0                    pypi_0    pypi\n",
      "prettytable               3.6.0                    pypi_0    pypi\n",
      "prometheus_client         0.16.0             pyhd8ed1ab_0    conda-forge\n",
      "promise                   2.3                      pypi_0    pypi\n",
      "prompt-toolkit            3.0.38             pyha770c72_0    conda-forge\n",
      "proto-plus                1.22.2                   pypi_0    pypi\n",
      "protobuf                  3.19.6                   pypi_0    pypi\n",
      "psutil                    5.9.3            py37h540881e_0    conda-forge\n",
      "ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\n",
      "py-spy                    0.3.14                   pypi_0    pypi\n",
      "pyarrow                   6.0.1                    pypi_0    pypi\n",
      "pyasn1                    0.4.8                      py_0    conda-forge\n",
      "pyasn1-modules            0.2.8                    pypi_0    pypi\n",
      "pycosat                   0.6.4            py37h540881e_0    conda-forge\n",
      "pycparser                 2.21               pyhd3eb1b0_0  \n",
      "pydantic                  1.10.7                   pypi_0    pypi\n",
      "pydot                     1.4.2                    pypi_0    pypi\n",
      "pygments                  2.14.0             pyhd8ed1ab_0    conda-forge\n",
      "pyjwt                     2.6.0                    pypi_0    pypi\n",
      "pymongo                   3.13.0                   pypi_0    pypi\n",
      "pyopenssl                 23.1.0             pyhd8ed1ab_0    conda-forge\n",
      "pyparsing                 3.0.9                    pypi_0    pypi\n",
      "pyrsistent                0.19.3                   pypi_0    pypi\n",
      "pysocks                   1.7.1                    py37_1  \n",
      "python                    3.7.12          hf930737_100_cpython    conda-forge\n",
      "python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\n",
      "python-fastjsonschema     2.16.3             pyhd8ed1ab_0    conda-forge\n",
      "python_abi                3.7                     3_cp37m    conda-forge\n",
      "pytz                      2023.2                   pypi_0    pypi\n",
      "pyu2f                     0.1.5              pyhd8ed1ab_0    conda-forge\n",
      "pywavelets                1.3.0                    pypi_0    pypi\n",
      "pyyaml                    6.0                      pypi_0    pypi\n",
      "pyzmq                     25.0.2                   pypi_0    pypi\n",
      "ray                       2.3.1                    pypi_0    pypi\n",
      "ray-cpp                   2.3.1                    pypi_0    pypi\n",
      "re2                       2022.06.01           h27087fc_1    conda-forge\n",
      "readline                  8.2                  h8228510_1    conda-forge\n",
      "regex                     2022.10.31               pypi_0    pypi\n",
      "requests                  2.28.2             pyhd8ed1ab_0    conda-forge\n",
      "requests-oauthlib         1.3.1                    pypi_0    pypi\n",
      "retrying                  1.3.4                    pypi_0    pypi\n",
      "rich                      13.3.2                   pypi_0    pypi\n",
      "rsa                       4.9                pyhd8ed1ab_0    conda-forge\n",
      "ruamel_yaml               0.15.100         py37h27cfd23_0  \n",
      "scikit-image              0.19.3                   pypi_0    pypi\n",
      "scikit-learn              1.0.2                    pypi_0    pypi\n",
      "scipy                     1.7.3                    pypi_0    pypi\n",
      "seaborn                   0.12.2                   pypi_0    pypi\n",
      "secretstorage             3.3.3                    pypi_0    pypi\n",
      "send2trash                1.8.0              pyhd8ed1ab_0    conda-forge\n",
      "setuptools                67.6.0             pyhd8ed1ab_0    conda-forge\n",
      "shapely                   1.8.5.post1              pypi_0    pypi\n",
      "simpervisor               0.4                      pypi_0    pypi\n",
      "six                       1.16.0             pyhd3eb1b0_1  \n",
      "smart-open                6.3.0                    pypi_0    pypi\n",
      "smmap                     5.0.0                    pypi_0    pypi\n",
      "sniffio                   1.3.0              pyhd8ed1ab_0    conda-forge\n",
      "soupsieve                 2.4                      pypi_0    pypi\n",
      "sqlalchemy                2.0.7                    pypi_0    pypi\n",
      "sqlite                    3.40.0               h4ff8645_0    conda-forge\n",
      "sqlparse                  0.4.3                    pypi_0    pypi\n",
      "starlette                 0.26.1                   pypi_0    pypi\n",
      "statsmodels               0.13.5                   pypi_0    pypi\n",
      "tabulate                  0.9.0                    pypi_0    pypi\n",
      "tangled-up-in-unicode     0.2.0                    pypi_0    pypi\n",
      "tenacity                  8.2.2                    pypi_0    pypi\n",
      "tensorboard               2.10.1                   pypi_0    pypi\n",
      "tensorboard-data-server   0.6.1                    pypi_0    pypi\n",
      "tensorboard-plugin-profile 2.11.2                   pypi_0    pypi\n",
      "tensorboard-plugin-wit    1.8.1                    pypi_0    pypi\n",
      "tensorboardx              2.6                      pypi_0    pypi\n",
      "tensorflow                2.10.1                   pypi_0    pypi\n",
      "tensorflow-cloud          0.1.16                   pypi_0    pypi\n",
      "tensorflow-datasets       4.8.2                    pypi_0    pypi\n",
      "tensorflow-estimator      2.10.0                   pypi_0    pypi\n",
      "tensorflow-hub            0.13.0                   pypi_0    pypi\n",
      "tensorflow-io             0.27.0                   pypi_0    pypi\n",
      "tensorflow-io-gcs-filesystem 0.27.0                   pypi_0    pypi\n",
      "tensorflow-metadata       1.11.0                   pypi_0    pypi\n",
      "tensorflow-probability    0.19.0                   pypi_0    pypi\n",
      "tensorflow-serving-api    2.10.1                   pypi_0    pypi\n",
      "tensorflow-transform      1.11.0                   pypi_0    pypi\n",
      "termcolor                 2.2.0                    pypi_0    pypi\n",
      "terminado                 0.17.1             pyh41d4057_0    conda-forge\n",
      "textwrap3                 0.9.2                    pypi_0    pypi\n",
      "tfx-bsl                   1.11.0                   pypi_0    pypi\n",
      "threadpoolctl             3.1.0                    pypi_0    pypi\n",
      "tifffile                  2021.11.2                pypi_0    pypi\n",
      "tinycss2                  1.2.1              pyhd8ed1ab_0    conda-forge\n",
      "tk                        8.6.12               h27826a3_0    conda-forge\n",
      "toml                      0.10.2                   pypi_0    pypi\n",
      "tomli                     2.0.1                    pypi_0    pypi\n",
      "toolz                     0.12.0             pyhd8ed1ab_0    conda-forge\n",
      "tornado                   6.2              py37h540881e_0    conda-forge\n",
      "tqdm                      4.64.1                   pypi_0    pypi\n",
      "traitlets                 5.9.0              pyhd8ed1ab_0    conda-forge\n",
      "typeguard                 2.13.3                   pypi_0    pypi\n",
      "typer                     0.7.0                    pypi_0    pypi\n",
      "typing-extensions         4.5.0                hd8ed1ab_0    conda-forge\n",
      "typing_extensions         4.5.0              pyha770c72_0    conda-forge\n",
      "uritemplate               3.0.1                    pypi_0    pypi\n",
      "urllib3                   1.26.15            pyhd8ed1ab_0    conda-forge\n",
      "uvicorn                   0.21.1                   pypi_0    pypi\n",
      "virtualenv                20.21.0                  pypi_0    pypi\n",
      "visions                   0.7.5                    pypi_0    pypi\n",
      "wcwidth                   0.2.6              pyhd8ed1ab_0    conda-forge\n",
      "webencodings              0.5.1                    pypi_0    pypi\n",
      "websocket-client          1.5.1              pyhd8ed1ab_0    conda-forge\n",
      "werkzeug                  2.1.2                    pypi_0    pypi\n",
      "wheel                     0.40.0             pyhd8ed1ab_0    conda-forge\n",
      "widgetsnbextension        4.0.6                    pypi_0    pypi\n",
      "witwidget                 1.8.1                    pypi_0    pypi\n",
      "wrapt                     1.15.0                   pypi_0    pypi\n",
      "xz                        5.2.6                h166bdaf_0    conda-forge\n",
      "yaml                      0.2.5                h7b6447c_0  \n",
      "yarl                      1.8.2                    pypi_0    pypi\n",
      "ydata-profiling           4.1.1                    pypi_0    pypi\n",
      "zeromq                    4.3.4                h9c3ff4c_1    conda-forge\n",
      "zipp                      3.15.0             pyhd8ed1ab_0    conda-forge\n",
      "zlib                      1.2.13               h166bdaf_4    conda-forge\n",
      "zstandard                 0.18.0           py37h540881e_0    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e1cfad-d8c2-4592-8a19-c5369683803a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b8d80a-4a50-461e-9b6b-2e3fe46e3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiHClassifier(tf.keras.Model):\n",
    "    def __init__(self, number_of_output_classes: int,\n",
    "                 image_shape: Tuple[int, int, int] = (224, 224, 3)):\n",
    "        super().__init__()\n",
    "        self.number_of_output_classes: int = number_of_output_classes\n",
    "        self.image_shape: Tuple[int, int, int] = image_shape\n",
    "\n",
    "        self.pretrained_resnet50 = tf.keras.applications.resnet50.ResNet50(include_top=False,\n",
    "                                                                           weights=\"imagenet\",\n",
    "                                                                           input_shape=image_shape)\n",
    "        self.pretrained_resnet50.trainable = False\n",
    "\n",
    "        self.global_average_pooling = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.prediction_layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(self.number_of_output_classes, activation=tf.keras.activations.sigmoid)\n",
    "        ])\n",
    "\n",
    "        self.build(input_shape=(None, image_shape[0], image_shape[1], image_shape[2]))\n",
    "\n",
    "    def unfreeze_top_layers(self, fine_tune_top_n: int):\n",
    "        self.pretrained_resnet50.trainable = True\n",
    "\n",
    "        number_of_layers: int = len(self.pretrained_resnet50.layers)\n",
    "        layers_to_freeze: int = number_of_layers - fine_tune_top_n\n",
    "\n",
    "        for i in range(layers_to_freeze):\n",
    "            self.pretrained_resnet50.layers[i].trainable = False\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        resnet_features = self.pretrained_resnet50(inputs, training=training)\n",
    "        avg_pooling_features = self.global_average_pooling(resnet_features)\n",
    "        predictions = self.prediction_layer(avg_pooling_features)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51494597-340c-492c-a80e-e1b2aee81c05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Google cloud storage interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99bb73b5-2ea7-4f9c-8ab3-9f4722577ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_bucket(BUCKET_NAME):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(BUCKET_NAME)\n",
    "    return bucket\n",
    "\n",
    "def open_file_gcs(path_to_file: str, bucket, mode: str):\n",
    "    blob = bucket.blob(path_to_file)\n",
    "    return blob.open(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c070bd2-2b49-479e-b8c7-1b52de81814c",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e13a75-61b0-4740-a05a-f231577dd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_data_augmentation(file_path, label):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_image(image, channels=3, dtype=tf.float32)\n",
    "    if tf.random.uniform(shape=[]) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def read_image(file_path, label):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_image(image, channels=3, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def scheduler(epoch: int, lr: float) -> float:\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "def load_dataset(path_to_images: str,\n",
    "                 path_to_pkl: str,\n",
    "                 model_type: str,\n",
    "                 batch_size: int,\n",
    "                 data_augmentation: bool = False) -> tf.data.Dataset:\n",
    "    df = pd.read_pickle(path_to_pkl)\n",
    "    df['Image Index'] = path_to_images + df['Image Index']\n",
    "\n",
    "    x = df['Image Index'].values\n",
    "    if model_type == \"Binary\":\n",
    "        y = df['No Finding'].values\n",
    "    else:\n",
    "        y = np.stack(df['multi_category_labels'].values)\n",
    "\n",
    "    if data_augmentation:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((x, y)).map(read_image_data_augmentation).batch(batch_size=batch_size)\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((x, y)).map(read_image).batch(batch_size=batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_history(history, path: str):\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "\n",
    "    history_dict = history.history\n",
    "    # Save it under the form of a json file\n",
    "    s = str(history_dict)\n",
    "    with open(path, 'w') as file:\n",
    "        file.write(s)\n",
    "\n",
    "\n",
    "def plot_loss_acc(history, path: str, model_type: str):\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    if model_type == 'Binary':\n",
    "        train_acc = history.history['accuracy']\n",
    "        val_acc = history.history['val_accuracy']\n",
    "\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(train_acc, label='Training Accuracy')\n",
    "        plt.plot(val_acc, label='Validation Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.ylim([min(plt.ylim()), 1])\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "    else:\n",
    "        train_auc = history.history['auc']\n",
    "        val_auc = history.history['val_auc']\n",
    "\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(train_auc, label='Training AUC')\n",
    "        plt.plot(val_auc, label='Validation AUC')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.ylim([min(plt.ylim()), 1])\n",
    "        plt.title('Training and Validation AUC')\n",
    "\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc35a23-77f8-468e-9bb1-9f9083c5cdef",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9f2f6c-643b-43fb-b29c-0e786abe18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'dldsproject'\n",
    "\n",
    "path_to_training_images: str = 'gs://dldsproject/NiH/images_resized/train/'\n",
    "path_to_validation_images: str = 'gs://dldsproject/NiH/images_resized/val/'\n",
    "path_to_test_images: str = 'gs://dldsproject/NiH/images_resized/test/'\n",
    "path_to_training_pkl: str = 'gs://dldsproject/NiH/training_data_extended_4.pkl'\n",
    "path_to_validation_pkl: str = 'gs://dldsproject/NiH/validation_data_extended_4.pkl'\n",
    "path_to_test_pkl: str = 'gs://dldsproject/NiH/test_data_extended_4.pkl'\n",
    "\n",
    "batch_size: int = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d47dedc-2f48-4061-a9c7-5ab3e9486b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:25:25.426958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 15:25:25.447056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 15:25:25.450661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 15:25:25.453305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 15:25:33.263656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 15:25:33.266472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 15:25:33.268130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-20 15:25:33.269697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "binary_train_ds = load_dataset(path_to_training_images,\n",
    "                               path_to_training_pkl,\n",
    "                               model_type='Binary',\n",
    "                               batch_size=batch_size,\n",
    "                               data_augmentation=False)\n",
    "binary_val_ds = load_dataset(path_to_training_images,\n",
    "                             path_to_training_pkl,\n",
    "                             model_type='Binary',\n",
    "                             batch_size=batch_size,\n",
    "                             data_augmentation=False)\n",
    "binary_test_ds = load_dataset(path_to_training_images,\n",
    "                              path_to_training_pkl,\n",
    "                              model_type='Binary',\n",
    "                              batch_size=batch_size,\n",
    "                              data_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f42c94-2b1c-4027-8332-fcf967feceb3",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f64658-3e18-4f55-825c-87de6adabeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_dataset,\n",
    "          validation_dataset,\n",
    "          initial_epochs: int,\n",
    "          fine_tuning_epochs: int,\n",
    "          lr: float,\n",
    "          fine_tune_at: int,\n",
    "          lr_scheduler: bool,\n",
    "          model_type: str = 'Binary'):\n",
    "    \n",
    "    number_of_output_classes: int = 1 if model_type == 'Binary' else 15\n",
    "    \n",
    "    loss: tf.keras.losses\n",
    "    metric: List[tf.keras.metrics]\n",
    "    if model_type == 'Binary':\n",
    "        loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        metric = ['accuracy']\n",
    "    else:\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "        metric = [tf.keras.metrics.AUC()]\n",
    "\n",
    "    callbacks = []\n",
    "    if lr_scheduler:\n",
    "        callback_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "        callbacks.append(callback_scheduler)\n",
    "        \n",
    "    # monitor: str = 'val_accuracy' if model_type == 'Binary' else 'val_auc'\n",
    "    # model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    #     filepath=os.path.join(path_to_save_models, 'checkpoints'),\n",
    "    #     save_weights_only=True,\n",
    "    #     monitor=monitor,\n",
    "    #     mode='max',\n",
    "    #     save_best_only=True)\n",
    "    # callbacks.append(model_checkpoint_callback)\n",
    "    \n",
    "    nih_classifier: NiHClassifier = NiHClassifier(number_of_output_classes=number_of_output_classes)\n",
    "    nih_classifier.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           loss=loss,\n",
    "                           metrics=metric)\n",
    "\n",
    "    training_history = nih_classifier.fit(training_dataset,\n",
    "                                          epochs=initial_epochs,\n",
    "                                          validation_data=validation_dataset,\n",
    "                                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe67eda-6c00-40b5-8eaf-a4d28fd1ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs: int = 10\n",
    "fine_tuning_epochs: int = 10\n",
    "lr: float = 1e-4\n",
    "fine_tune_at: int = 45\n",
    "lr_scheduler: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eab48328-43c6-46b5-9e13-74f107da03f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:26:08.225279: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
      "2023-05-20 15:26:17.335552: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-20 15:26:17.336364: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-20 15:26:17.336435: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-05-20 15:26:17.337366: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-20 15:26:17.337495: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9/1077 [..............................] - ETA: 1:56:01 - loss: 0.7648 - accuracy: 0.4653"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/3016140130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mfine_tune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfine_tune_at\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       model_type='Binary')\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1/909014460.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training_dataset, validation_dataset, initial_epochs, fine_tuning_epochs, lr, fine_tune_at, lr_scheduler, model_type)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                           callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(binary_train_ds,\n",
    "      binary_val_ds,\n",
    "      initial_epochs=initial_epochs,\n",
    "      fine_tuning_epochs=fine_tuning_epochs,\n",
    "      lr=lr,\n",
    "      fine_tune_at=fine_tune_at,\n",
    "      lr_scheduler=lr_scheduler,\n",
    "      model_type='Binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3fdbf-b7d0-4cdd-8da4-036717360310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
