{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REbLctzTP5zi",
        "outputId": "523a3a28-6c80-4635-bf17-6cb9d1454509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vit-keras in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vit-keras) (1.10.1)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.10/dist-packages (from vit-keras) (0.20.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->vit-keras) (1.22.4)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators->vit-keras) (4.4.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install vit-keras\n",
        "!pip install tensorflow_addons\n",
        "from vit_keras import vit\n",
        "import tensorflow as tf\n",
        "from typing import *\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIgISpNgcN4x",
        "outputId": "7b66a519-ddd3-4ad5-ec1e-dec9cd8e1302"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "14U6f3F-cSFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model = vit.vit_b16(\n",
        "        image_size=224,\n",
        "        activation='softmax',\n",
        "        pretrained=True,\n",
        "        include_top=False,\n",
        "        pretrained_top=False,\n",
        "        classes=44)\n",
        "\n",
        "for layer in vit_model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "PcCyQe79P_yM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initializer = tf.keras.initializers.GlorotNormal(seed=CFG_SEED)"
      ],
      "metadata": {
        "id": "60_Lwbcqo_YF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vit_b16_model():    \n",
        "    vit_b16_sequential = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(224,224,3), dtype=tf.float32, name='input_image'),\n",
        "        vit_model,\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(512, activation='relu', kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(256, activation='relu', kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(44, dtype=tf.float32, activation='softmax', kernel_initializer=initializer)\n",
        "    ], name='vit_b16_sequential_model')\n",
        "    \n",
        "    return vit_b16_sequential"
      ],
      "metadata": {
        "id": "I6m6IyaRROJ_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Model\n",
        "model_vit_b16 = vit_b16_model()\n",
        "\n",
        "# Generate Summary of the Model\n",
        "model_vit_b16.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrDSynRpRR6O",
        "outputId": "e8e583b5-3efe-48a4-ba8a-72c53e2b7ed6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vit_b16_sequential_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vit-b16 (Functional)        (None, 768)               85798656  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               393728    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 44)                11308     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86,335,020\n",
            "Trainable params: 536,364\n",
            "Non-trainable params: 85,798,656\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG_SEED=71\n",
        "NUM_EPOCHS = 2"
      ],
      "metadata": {
        "id": "o_JNuhbXRUZ1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    #directory='training_data/',\n",
        "    directory='/content/drive/MyDrive/Colab Notebooks/training_data',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224))\n",
        "\n",
        "\n",
        "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    #directory='validation_data/',\n",
        "    directory='/content/drive/MyDrive/Colab Notebooks/validation_data',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpBq7Hy2RW18",
        "outputId": "fce64d07-0c13-4f83-9cd1-d760f4e1c985"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3581 files belonging to 44 classes.\n",
            "Found 895 files belonging to 44 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_batches = tf.data.experimental.cardinality(validation_ds)\n",
        "print('Number of val batches: %d' % val_batches)\n",
        "test_dataset = validation_ds.take(val_batches // 5)\n",
        "validation_data = validation_ds.skip(val_batches // 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saexv1wvqlxQ",
        "outputId": "8f3e06af-3e1e-4c8a-bb1c-b20372094ca8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of val batches: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "val_ds = validation_data.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "test_ds = test_dataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n"
      ],
      "metadata": {
        "id": "ogsmbQotqbZK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_batches = tf.data.experimental.cardinality(validation_ds)\n",
        "# print('Number of val batches: %d' % val_batches)\n",
        "# test_dataset = validation_ds.take(val_batches // 5)\n",
        "# validation_data = validation_ds.skip(val_batches // 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lmwpqq-RYsK",
        "outputId": "14de4848-1aba-480e-98de-d1008bfe8175"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of val batches: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(CFG_SEED)\n",
        "\n",
        "# Compile the model\n",
        "model_vit_b16.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    # loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model_vit_b16.fit(train_ds,validation_data=val_ds, epochs=NUM_EPOCHS)\n",
        "print(model_vit_b16.evaluate(test_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwfFPII5e5MP",
        "outputId": "5504ea64-8d57-4b51-a681-fcc59c2e6c35"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "112/112 [==============================] - 2820s 25s/step - loss: 2.5552 - accuracy: 0.3250 - val_loss: 1.9654 - val_accuracy: 0.4395\n",
            "Epoch 2/2\n",
            "112/112 [==============================] - 2754s 25s/step - loss: 1.6741 - accuracy: 0.5035 - val_loss: 1.5377 - val_accuracy: 0.5401\n",
            "5/5 [==============================] - 98s 20s/step - loss: 1.7411 - accuracy: 0.4500\n",
            "[1.7410808801651, 0.44999998807907104]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 2 EPOCHS TRAINING: \n",
        "#Epoch 1/2\n",
        "# 112/112 [==============================] - 2820s 25s/step - loss: 2.5552 - accuracy: 0.3250 - val_loss: 1.9654 - val_accuracy: 0.4395\n",
        "# Epoch 2/2\n",
        "# 112/112 [==============================] - 2754s 25s/step - loss: 1.6741 - accuracy: 0.5035 - val_loss: 1.5377 - val_accuracy: 0.5401\n",
        "# 1/5 [=====>........................] - ETA: 1:13 - loss: 1.6646 - accuracy: 0.4375\n",
        "\n",
        "\n",
        "#5/5 [==============================] - 98s 20s/step - loss: 1.7411 - accuracy: 0.4500\n",
        "# [1.7410808801651, 0.44999998807907104]"
      ],
      "metadata": {
        "id": "VzYmppaffElQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}