{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "SEED=100\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_train_val(data_list, normal_list, train_prop, val_prop, test_prop):\n",
    "    if (train_prop + val_prop + test_prop) != 1:\n",
    "        raise (\"The sum of the proportions must be 1\")\n",
    "\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    test_list = []\n",
    "\n",
    "    np.random.shuffle(data_list)\n",
    "    np.random.shuffle(normal_list)\n",
    "\n",
    "    n = len(data_list)\n",
    "    m = len(normal_list)\n",
    "\n",
    "    train_lim_unnormal = int(train_prop * n)\n",
    "    train_lim_normal = int(train_prop * m)\n",
    "    val_lim_unnormal = int(val_prop * n)\n",
    "    val_lim_normal = int(val_prop * m)\n",
    "\n",
    "    train_list_unnormal = data_list[:train_lim_unnormal]\n",
    "    train_list_normal = normal_list[:train_lim_normal]\n",
    "    train_list = [*train_list_unnormal, *train_list_normal]\n",
    "\n",
    "    val_list_unnormal = data_list[train_lim_unnormal:train_lim_unnormal + val_lim_unnormal]\n",
    "    val_list_normal = normal_list[train_lim_normal:train_lim_normal + val_lim_normal]\n",
    "    val_list = [*val_list_unnormal, *val_list_normal]\n",
    "\n",
    "    test_list_unnormal = data_list[train_lim_unnormal + val_lim_unnormal:]\n",
    "    test_list_normal = normal_list[train_lim_normal + val_lim_normal:]\n",
    "    test_list = [*test_list_unnormal, *test_list_normal]\n",
    "\n",
    "    return train_list, val_list, test_list\n",
    "\n",
    "\n",
    "\n",
    "def create_files(file_names, folder_path):\n",
    "    path_extract = \"resized_images/\"\n",
    "    filenames = os.listdir(path_extract)\n",
    "    #new_path = 'training_data/'\n",
    "    new_path = folder_path\n",
    "\n",
    "    #instead of file_names, put train, val or test:\n",
    "    for image in file_names:\n",
    "        image_name = image[0]\n",
    "        image_class = image[1]\n",
    "\n",
    "        im_path = os.path.join(path_extract, image_class, image_name)\n",
    "        new_folder_path = os.path.join(new_path, image_class)\n",
    "\n",
    "        if not os.path.exists(new_folder_path):\n",
    "            os.makedirs(new_folder_path)\n",
    "        new_im_path = os.path.join(new_folder_path, image_name)\n",
    "        image_file = cv2.imread(im_path)\n",
    "        cv2.imwrite(new_im_path, image_file)\n",
    "\n",
    "    # Make sure the folder contains a file for each of the 44 categories:\n",
    "    for file in filenames:\n",
    "        new_folder_path = os.path.join(new_path, file)\n",
    "        if not os.path.exists(new_folder_path):\n",
    "            os.makedirs(new_folder_path)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "normal_list = []\n",
    "with open('data_list.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        image_list = line.split(\";\")\n",
    "        if \"_NORMAL\" in image_list[1]:\n",
    "            normal_list.append([image_list[0], image_list[1].replace('\\n', '')])\n",
    "        else:\n",
    "            data_list.append([image_list[0], image_list[1].replace('\\n', '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = store_train_val(data_list, normal_list, 0.8, 0.2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_files(train, 'training_data/')\n",
    "create_files(val, 'validation_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='training_data/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224))\n",
    "\n",
    "\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='validation_data/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(train_ds.class_names)\n",
    "val_batches = tf.data.experimental.cardinality(validation_ds)\n",
    "test_dataset = validation_ds.take(val_batches // 5)\n",
    "validation_data = validation_ds.skip(val_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_layer = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode='horizontal')\n",
    "], name='augmentation_layer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = validation_data\n",
    "test_ds = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "inception_v3 = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"\n",
    "resnet50 = \"https://tfhub.dev/tensorflow/resnet_50/classification/1\"\n",
    "resnet50_v2 = 'https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5'\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "feature_extractor_model = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNetRS152(input_shape=(224, 224, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(224, 224, 3),\n",
    "                          dtype=tf.float32, name='input_image'),\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(\n",
    "        num_classes, dtype=tf.float32, activation='softmax')\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
