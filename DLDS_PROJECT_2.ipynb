{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REbLctzTP5zi",
        "outputId": "dd077017-aede-4c88-87db-fdc509775424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vit-keras\n",
            "  Downloading vit_keras-0.1.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vit-keras) (1.10.1)\n",
            "Collecting validators (from vit-keras)\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->vit-keras) (1.22.4)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators->vit-keras) (4.4.2)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=4bc453194753a2b81c60f75b2a0c09e1788927bccd823942f3a5a18fa8eaca46\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built validators\n",
            "Installing collected packages: validators, vit-keras\n",
            "Successfully installed validators-0.20.0 vit-keras-0.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install vit-keras\n",
        "!pip install tensorflow_addons\n",
        "from vit_keras import vit\n",
        "import tensorflow as tf\n",
        "from typing import *\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIgISpNgcN4x",
        "outputId": "b49c7860-d223-448e-cee0-5d0972654848"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "14U6f3F-cSFz"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model = vit.vit_b16(\n",
        "        image_size=224,\n",
        "        activation='softmax',\n",
        "        pretrained=True,\n",
        "        include_top=False,\n",
        "        pretrained_top=False,\n",
        "        classes=44)\n",
        "\n",
        "for layer in vit_model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcCyQe79P_yM",
        "outputId": "03ee235c-ad2a-4a3b-df9b-e420064f2590"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_16_imagenet21k+imagenet2012.npz\n",
            "347502902/347502902 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initializer = tf.keras.initializers.GlorotNormal(seed=CFG_SEED)"
      ],
      "metadata": {
        "id": "60_Lwbcqo_YF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vit_b16_model():    \n",
        "    vit_b16_sequential = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(224,224,3), dtype=tf.float32, name='input_image'),\n",
        "        vit_model,\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        #, kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        # kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(44, dtype=tf.float32, activation='softmax'),\n",
        "        #, kernel_initializer=initializer)\n",
        "    ], name='vit_b16_sequential_model')\n",
        "    \n",
        "    return vit_b16_sequential"
      ],
      "metadata": {
        "id": "I6m6IyaRROJ_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Model\n",
        "model_vit_b16 = vit_b16_model()\n",
        "\n",
        "# Generate Summary of the Model\n",
        "model_vit_b16.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrDSynRpRR6O",
        "outputId": "ed10fa3d-be89-41d7-da44-dad79beaa852"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vit_b16_sequential_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vit-b16 (Functional)        (None, 768)               85798656  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 768)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               393728    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 44)                11308     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86,335,020\n",
            "Trainable params: 536,364\n",
            "Non-trainable params: 85,798,656\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG_SEED=71\n",
        "NUM_EPOCHS = 25"
      ],
      "metadata": {
        "id": "o_JNuhbXRUZ1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    #directory='training_data/',\n",
        "    directory='/content/drive/MyDrive/Colab Notebooks/training_data',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224))\n",
        "\n",
        "\n",
        "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    #directory='validation_data/',\n",
        "    directory='/content/drive/MyDrive/Colab Notebooks/validation_data',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpBq7Hy2RW18",
        "outputId": "9220170a-b59e-4739-aaf9-a514d538b457"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3581 files belonging to 44 classes.\n",
            "Found 895 files belonging to 44 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_batches = tf.data.experimental.cardinality(validation_ds)\n",
        "print('Number of val batches: %d' % val_batches)\n",
        "test_dataset = validation_ds.take(val_batches // 5)\n",
        "validation_data = validation_ds.skip(val_batches // 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saexv1wvqlxQ",
        "outputId": "7ffa64b3-65d1-40b0-89a7-c01e216545fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of val batches: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "val_ds = validation_data.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "test_ds = test_dataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n"
      ],
      "metadata": {
        "id": "ogsmbQotqbZK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_batches = tf.data.experimental.cardinality(validation_ds)\n",
        "# print('Number of val batches: %d' % val_batches)\n",
        "# test_dataset = validation_ds.take(val_batches // 5)\n",
        "# validation_data = validation_ds.skip(val_batches // 5)"
      ],
      "metadata": {
        "id": "-Lmwpqq-RYsK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Early Stopping Callback\n",
        "earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    patience=3)\n",
        "callbacks_list = [earlystopping_callback]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qDJOd1NoJBmm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(CFG_SEED)\n",
        "\n",
        "# Compile the model\n",
        "model_vit_b16.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    # loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model_vit_b16.fit(train_ds,validation_data=val_ds, epochs=NUM_EPOCHS, callbacks=callbacks_list)\n",
        "print(model_vit_b16.evaluate(test_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwfFPII5e5MP",
        "outputId": "af94e934-8d32-4561-dd37-6dc43f94a38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "112/112 [==============================] - 3784s 33s/step - loss: 2.5959 - accuracy: 0.3083 - val_loss: 1.9170 - val_accuracy: 0.4517\n",
            "Epoch 2/25\n",
            "112/112 [==============================] - 3741s 33s/step - loss: 1.6855 - accuracy: 0.5110 - val_loss: 1.6071 - val_accuracy: 0.5279\n",
            "Epoch 3/25\n",
            "112/112 [==============================] - 3639s 33s/step - loss: 1.3819 - accuracy: 0.5845 - val_loss: 1.2227 - val_accuracy: 0.6259\n",
            "Epoch 4/25\n",
            "112/112 [==============================] - 3633s 32s/step - loss: 1.2015 - accuracy: 0.6336 - val_loss: 1.1652 - val_accuracy: 0.6204\n",
            "Epoch 5/25\n",
            "112/112 [==============================] - 3843s 34s/step - loss: 1.0483 - accuracy: 0.6772 - val_loss: 1.0837 - val_accuracy: 0.6721\n",
            "Epoch 6/25\n",
            "112/112 [==============================] - 3801s 34s/step - loss: 0.9532 - accuracy: 0.6995 - val_loss: 1.1302 - val_accuracy: 0.6571\n",
            "Epoch 7/25\n",
            "112/112 [==============================] - 3859s 34s/step - loss: 0.8864 - accuracy: 0.7177 - val_loss: 1.0939 - val_accuracy: 0.6707\n",
            "Epoch 8/25\n",
            "112/112 [==============================] - 3901s 35s/step - loss: 0.8042 - accuracy: 0.7436 - val_loss: 0.9823 - val_accuracy: 0.6993\n",
            "Epoch 9/25\n",
            "112/112 [==============================] - 3876s 35s/step - loss: 0.7441 - accuracy: 0.7618 - val_loss: 0.9520 - val_accuracy: 0.6993\n",
            "Epoch 10/25\n",
            "112/112 [==============================] - 3743s 33s/step - loss: 0.6834 - accuracy: 0.7788 - val_loss: 1.0451 - val_accuracy: 0.6776\n",
            "Epoch 11/25\n",
            "112/112 [==============================] - 3594s 32s/step - loss: 0.6466 - accuracy: 0.7894 - val_loss: 1.0207 - val_accuracy: 0.6966\n",
            "Epoch 12/25\n",
            " 55/112 [=============>................] - ETA: 25:52 - loss: 0.5895 - accuracy: 0.8142"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9: Plot loss and accuracies:\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MLUIVIfZTH7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 2 EPOCHS TRAINING: \n",
        "#Epoch 1/2\n",
        "# 112/112 [==============================] - 2820s 25s/step - loss: 2.5552 - accuracy: 0.3250 - val_loss: 1.9654 - val_accuracy: 0.4395\n",
        "# Epoch 2/2\n",
        "# 112/112 [==============================] - 2754s 25s/step - loss: 1.6741 - accuracy: 0.5035 - val_loss: 1.5377 - val_accuracy: 0.5401\n",
        "# 1/5 [=====>........................] - ETA: 1:13 - loss: 1.6646 - accuracy: 0.4375\n",
        "\n",
        "\n",
        "#5/5 [==============================] - 98s 20s/step - loss: 1.7411 - accuracy: 0.4500\n",
        "# [1.7410808801651, 0.44999998807907104]"
      ],
      "metadata": {
        "id": "VzYmppaffElQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}