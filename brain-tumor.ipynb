{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65ab3708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/farhad/anaconda3/lib/python3.10/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/farhad/.local/lib/python3.10/site-packages (from opencv-python) (1.23.3)\n",
      "Requirement already satisfied: opendatasets in /home/farhad/anaconda3/lib/python3.10/site-packages (0.1.22)\n",
      "Requirement already satisfied: kaggle in /home/farhad/anaconda3/lib/python3.10/site-packages (from opendatasets) (1.5.13)\n",
      "Requirement already satisfied: tqdm in /home/farhad/.local/lib/python3.10/site-packages (from opendatasets) (4.65.0)\n",
      "Requirement already satisfied: click in /home/farhad/anaconda3/lib/python3.10/site-packages (from opendatasets) (8.0.4)\n",
      "Requirement already satisfied: requests in /home/farhad/.local/lib/python3.10/site-packages (from kaggle->opendatasets) (2.28.2)\n",
      "Requirement already satisfied: urllib3 in /home/farhad/anaconda3/lib/python3.10/site-packages (from kaggle->opendatasets) (1.26.14)\n",
      "Requirement already satisfied: python-slugify in /home/farhad/anaconda3/lib/python3.10/site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil in /home/farhad/.local/lib/python3.10/site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: certifi in /home/farhad/anaconda3/lib/python3.10/site-packages (from kaggle->opendatasets) (2022.12.7)\n",
      "Requirement already satisfied: six>=1.10 in /home/farhad/anaconda3/lib/python3.10/site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/farhad/anaconda3/lib/python3.10/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/farhad/.local/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/farhad/anaconda3/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff007fd-1219-4d74-a8e1-ffcec6622d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78f01e12-8cf5-4821-aecc-a37eaf0394c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540ed1ef-73b2-46cd-a5b2-2f23ee98fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  faridashahata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading brain-tumor-mri-images-44c.zip to ./brain-tumor-mri-images-44c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188M/188M [00:03<00:00, 52.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# od.download(\"https://www.kaggle.com/datasets/fernando2rad/brain-tumor-mri-images-44c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b07f4df5-3d05-4733-ae76-ce882f5073b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4664563-2c08-4d88-81c7-e32519bcf1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resized-images',\n",
       " '.git',\n",
       " 'brain-tumor.ipynb',\n",
       " 'README.md',\n",
       " 'preprocessing.py',\n",
       " 'data_explorer.ipynb',\n",
       " '.gitignore',\n",
       " 'resize_images.py',\n",
       " 'preprocessing.ipynb',\n",
       " 'brain-tumor-mri-images-44c']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30bb42df-f78c-461f-a31b-6d5186696d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f074f6a-cb88-490a-adab-e31a8504af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9c35833-fdef-4636-bb1e-2786ebe59b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e96d71e8b4d9825c3d82fec0097cbf_big_gallery.jpeg\n"
     ]
    }
   ],
   "source": [
    "path_extract = \"brain-tumor-mri-images-44c/_NORMAL T1/\"\n",
    "filenames = os.listdir(\"brain-tumor-mri-images-44c/_NORMAL T1\")\n",
    "scans = []\n",
    "print(filenames[0])\n",
    "for f in filenames:\n",
    "#print(f)\n",
    "    img = Image.open(path_extract + f)\n",
    "    #print(\"IMG\", img)\n",
    "    matrix = np.array(img)\n",
    "    #print(\"MATRIX\", matrix)\n",
    "    scans.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d223d8ce-0a00-4427-bf19-8af1d224507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630, 630)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scans[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "169222e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_all_image_in_path(original_path: str, resized_path: str = './resized_images'):\n",
    "    if not os.path.exists(original_path):\n",
    "        print('Path does not exist')\n",
    "\n",
    "    if not os.path.exists(resized_path):\n",
    "        os.makedirs(resized_path)\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    files: List[str] = os.listdir(original_path)\n",
    "    for index, category in enumerate(files):\n",
    "        path = os.path.join(original_path, category)\n",
    "        for image in tqdm(os.listdir(path)):\n",
    "            original_file_path = os.path.join(path, image)\n",
    "            folder_path = os.path.join(resized_path, category)\n",
    "            \n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            new_file_path = os.path.join(folder_path,image)\n",
    "\n",
    "            image_file = cv2.imread(original_file_path)\n",
    "            resized_img = cv2.resize(image_file, dsize=(224, 224))\n",
    "            cv2.imwrite(new_file_path, resized_img)\n",
    "\n",
    "            data_list.append([image, category]) \n",
    "                \n",
    "                \n",
    "\n",
    "    with open('data_list.txt', 'w') as f:\n",
    "        for item in data_list:\n",
    "            f.write(f\"{item[0]};{item[1]}\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "    return data_list\n",
    "\n",
    "                # return      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e9e7d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files: List[str] = os.listdir(path_extract)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "291e28b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 129.61it/s]\n",
      "100%|██████████| 108/108 [00:00<00:00, 125.03it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 121.27it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 132.96it/s]\n",
      "100%|██████████| 123/123 [00:00<00:00, 131.81it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 138.46it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 174.00it/s]\n",
      "100%|██████████| 369/369 [00:02<00:00, 139.58it/s]\n",
      "100%|██████████| 45/45 [00:00<00:00, 136.70it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 126.62it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 91.01it/s]\n",
      "100%|██████████| 112/112 [00:00<00:00, 170.79it/s]\n",
      "100%|██████████| 251/251 [00:01<00:00, 142.70it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 129.26it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 102.65it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 123.15it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 178.32it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 138.31it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 127.36it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 134.37it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 124.60it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 142.12it/s]\n",
      "100%|██████████| 176/176 [00:01<00:00, 142.62it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 146.89it/s]\n",
      "100%|██████████| 223/223 [00:01<00:00, 141.55it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 131.33it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 138.40it/s]\n",
      "100%|██████████| 55/55 [00:00<00:00, 109.05it/s]\n",
      "100%|██████████| 94/94 [00:00<00:00, 132.62it/s]\n",
      "100%|██████████| 233/233 [00:01<00:00, 134.97it/s]\n",
      "100%|██████████| 271/271 [00:02<00:00, 107.47it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 119.41it/s]\n",
      "100%|██████████| 148/148 [00:01<00:00, 131.91it/s]\n",
      "100%|██████████| 233/233 [00:01<00:00, 140.69it/s]\n",
      "100%|██████████| 55/55 [00:00<00:00, 144.48it/s]\n",
      "100%|██████████| 57/57 [00:00<00:00, 112.20it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 108.38it/s]\n",
      "100%|██████████| 104/104 [00:00<00:00, 126.61it/s]\n",
      "100%|██████████| 66/66 [00:00<00:00, 146.02it/s]\n",
      "100%|██████████| 194/194 [00:01<00:00, 147.52it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 113.23it/s]\n",
      "100%|██████████| 171/171 [00:01<00:00, 129.14it/s]\n",
      "100%|██████████| 272/272 [00:01<00:00, 140.32it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 129.96it/s]\n"
     ]
    }
   ],
   "source": [
    "path_extract = \"brain-tumor-mri-images-44c/\"\n",
    "data_list = resize_all_image_in_path(path_extract, resized_path='./resized_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb138d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4479"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d6d89024-361e-4993-839c-8c3139fddc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:06<00:00, 40.88it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 39.35it/s]\n",
      "100%|██████████| 66/66 [00:02<00:00, 27.51it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 24.88it/s]\n",
      "100%|██████████| 112/112 [00:02<00:00, 49.54it/s]\n",
      "100%|██████████| 271/271 [00:11<00:00, 23.89it/s]\n",
      "100%|██████████| 73/73 [00:01<00:00, 49.61it/s]\n",
      "100%|██████████| 45/45 [00:01<00:00, 26.65it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 38.63it/s]\n",
      "100%|██████████| 223/223 [00:07<00:00, 31.70it/s]\n",
      "100%|██████████| 86/86 [00:03<00:00, 26.73it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 32.22it/s]\n",
      "100%|██████████| 123/123 [00:04<00:00, 27.38it/s]\n",
      "100%|██████████| 130/130 [00:04<00:00, 26.60it/s]\n",
      "100%|██████████| 104/104 [00:04<00:00, 23.37it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 24.87it/s]\n",
      "100%|██████████| 67/67 [00:02<00:00, 27.30it/s]\n",
      "100%|██████████| 194/194 [00:05<00:00, 34.65it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 34.35it/s]\n",
      "100%|██████████| 233/233 [00:09<00:00, 23.75it/s]\n",
      "100%|██████████| 55/55 [00:01<00:00, 39.74it/s]\n",
      "100%|██████████| 66/66 [00:02<00:00, 28.33it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 24.73it/s]\n",
      "100%|██████████| 41/41 [00:01<00:00, 21.98it/s]\n",
      "100%|██████████| 84/84 [00:02<00:00, 29.30it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 19.76it/s]\n",
      "100%|██████████| 72/72 [00:02<00:00, 29.26it/s]\n",
      "100%|██████████| 33/33 [00:01<00:00, 26.27it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 23.87it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 41.73it/s]\n",
      "100%|██████████| 233/233 [00:08<00:00, 28.79it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 21.79it/s]\n",
      "100%|██████████| 66/66 [00:01<00:00, 45.88it/s]\n",
      "100%|██████████| 176/176 [00:06<00:00, 25.59it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.21it/s]\n",
      "100%|██████████| 108/108 [00:03<00:00, 30.06it/s]\n",
      "100%|██████████| 33/33 [00:01<00:00, 22.50it/s]\n",
      "100%|██████████| 369/369 [00:14<00:00, 25.19it/s]\n",
      "100%|██████████| 94/94 [00:02<00:00, 43.71it/s]\n",
      "100%|██████████| 57/57 [00:02<00:00, 23.78it/s]\n",
      "100%|██████████| 171/171 [00:06<00:00, 28.35it/s]\n",
      "100%|██████████| 55/55 [00:01<00:00, 30.96it/s]\n",
      "100%|██████████| 148/148 [00:04<00:00, 31.05it/s]\n",
      "100%|██████████| 272/272 [00:10<00:00, 26.87it/s]\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "path_extract = \"brain-tumor-mri-images-44c/\"\n",
    "filenames = os.listdir(\"brain-tumor-mri-images-44c/\")\n",
    "\n",
    "\n",
    "for category in filenames:\n",
    "    path = os.path.join(path_extract, category)\n",
    "    #print(os.listdir(path))\n",
    "    for image in tqdm(os.listdir(path)):\n",
    "        im_path = os.path.join(path, image)\n",
    "        img = Image.open(im_path)\n",
    "    #print(\"IMG\", img)\n",
    "        matrix = np.array(img)\n",
    "        class_num = filenames.index(category)\n",
    "        # print(\"category:\", category)\n",
    "        # print(\"class number:\", class_num)\n",
    "        # print(matrix.shape)\n",
    "        # plt.imshow(img, cmap='gray')  # graph it\n",
    "        # plt.show() \n",
    "        \n",
    "        scaled_image = skimage.transform.resize(\n",
    "            matrix, (224, 224),\n",
    "            order=1,\n",
    "            mode='constant',\n",
    "            preserve_range=True)\n",
    "        # plt.imshow(scaled_image, cmap='gray')  # graph it\n",
    "        # plt.show() \n",
    "    #print(\"MATRIX\", matrix)\n",
    "        training_data.append([scaled_image, class_num])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aa4550af-933a-4dd4-bcbe-47b317feb575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4479"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "337a35bf-7c31-494f-9c59-1ea70deb5880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.26930075, 5.62275234, 5.6227933 , ..., 5.6227933 , 5.61085188,\n",
       "         4.63234202],\n",
       "        [5.62275234, 5.99991259, 5.99995629, ..., 5.99995629, 5.98721387,\n",
       "         4.94306801],\n",
       "        [5.6227933 , 5.99995629, 6.        , ..., 6.        , 5.98725748,\n",
       "         4.94310401],\n",
       "        ...,\n",
       "        [5.6227933 , 5.99995629, 6.        , ..., 6.        , 5.98725748,\n",
       "         4.94310401],\n",
       "        [5.61085188, 5.98721387, 5.98725748, ..., 5.99995559, 5.98721387,\n",
       "         4.94306801],\n",
       "        [4.63234202, 4.94306801, 4.94310401, ..., 5.62252876, 5.61085188,\n",
       "         4.63234202]]),\n",
       " 0]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef0c94f-53dd-4f5f-b65f-48b1f2c1c895",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_data[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "training_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f3bccacf-a3b7-4d66-bbca-4bfd3b8eeeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (224,224,3) into shape (224,224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_8013/1425870025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#print(X[0].reshape(-1, 224, 224, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (224,224,3) into shape (224,224)"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for image in training_data:\n",
    "   \n",
    "    X.append(image[0])\n",
    "   \n",
    "    y.append(image[1])\n",
    "\n",
    "# for features,label in training_data:\n",
    "#     X.append(features)\n",
    "#     y.append(label)\n",
    "\n",
    "#print(X[0].reshape(-1, 224, 224, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, 224, 224, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c245ebde-6697-4049-8d5d-56f62df55f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a4a5a0d-78b4-4c92-97c1-5477566a37c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_NORMAL T1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85c1b6f8-109b-4ed2-af2b-737fdd99703b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "553e9587-6844-4786-a8e2-d5f02b42eda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630, 630)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scans[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b85bf1cb-397e-4a0d-822b-24dbe392d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba0180af-44a0-4479-a5b5-f614ea497357",
   "metadata": {},
   "outputs": [],
   "source": [
    " image = skimage.transform.resize(\n",
    "            scans[0], (224, 224),\n",
    "            order=1,\n",
    "            mode='constant',\n",
    "            preserve_range=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebef2711-4173-42ac-a86b-1f1755b4bfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c53c2-bf48-4a1b-ae67-9c352a46cf7f",
   "metadata": {},
   "source": [
    "### NIH CHEST X-RAYS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da78a95-05de-463a-995a-916cd022d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  faridashahata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data.zip to ./data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42.0G/42.0G [07:48<00:00, 96.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/nih-chest-xrays/data\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be16ab9-0e04-471c-8cb7-4bf4054e8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/nih-chest-xrays/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee0ac6-04a7-4fcb-b175-271b133dafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow this to build training data:\n",
    "# https://www.kaggle.com/code/mekhdigakhramanian/loading-in-your-own-data-tensorflow-and-keras-p-2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eb3d80b7-6254-4c9b-871d-05ea4b276833",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data\"\n",
    "folder = [ x for x in os.listdir(path) if os.path.isdir(os.path.join(path,x))]\n",
    "\n",
    "paths_to_subfolders = [path+\"/\"+ i for i in folder]\n",
    "paths_to_images = [j + \"/images\" for j in paths_to_subfolders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "abc61164-5228-4875-80d8-72245e30c6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/images_010/images',\n",
       " './data/images_011/images',\n",
       " './data/images_008/images',\n",
       " './data/images_007/images',\n",
       " './data/images_012/images',\n",
       " './data/images_004/images',\n",
       " './data/images_003/images',\n",
       " './data/images_002/images',\n",
       " './data/images_006/images',\n",
       " './data/images_009/images',\n",
       " './data/images_001/images',\n",
       " './data/images_005/images']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_to_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54cccd-83d2-4e95-9eb5-02a4167d296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "training_data_2 = []\n",
    "for image_path in paths_to_images:\n",
    "    for image in os.listdir(image_path):\n",
    "        im_path = os.path.join(image_path, image)\n",
    "        im=Image.open(im_path)\n",
    "        image_list.append(im)\n",
    "        matrix = np.array(im)\n",
    "        scaled_img = skimage.transform.resize(matrix, (224, 224))\n",
    "        training_data_2.append(scaled_img)\n",
    "        #im.close()\n",
    "len(image_list)\n",
    "len(training_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12591c-2b71-4757-8897-eb8c10e36082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"training.pickle\", \"wb\")\n",
    "pickle_dump(training_data, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82389d-40f9-4c79-a190-53a53c0ddf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"training.pickle\", \"rb\")\n",
    "training = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28899f1f-f282-4e04-9173-339018c10822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data2 = []\n",
    "\n",
    "# path_extract = \"data/\"\n",
    "# filenames = os.listdir(\"brain-tumor-mri-images-44c/\")\n",
    "\n",
    "# for category in filenames:\n",
    "#     path = os.path.join(path_extract, category)\n",
    "#     #print(os.listdir(path))\n",
    "#     for image in tqdm(os.listdir(path)):\n",
    "#         im_path = os.path.join(path, image)\n",
    "#         img = Image.open(im_path)\n",
    "#     #print(\"IMG\", img)\n",
    "#         matrix = np.array(img)\n",
    "#         class_num = filenames.index(category)\n",
    "#         # print(\"category:\", category)\n",
    "#         # print(\"class number:\", class_num)\n",
    "#         # print(matrix.shape)\n",
    "#         # plt.imshow(img, cmap='gray')  # graph it\n",
    "#         # plt.show() \n",
    "        \n",
    "#         scaled_image = skimage.transform.resize(\n",
    "#             matrix, (224, 224),\n",
    "#             order=1,\n",
    "#             mode='constant',\n",
    "#             preserve_range=True)\n",
    "#         # plt.imshow(scaled_image, cmap='gray')  # graph it\n",
    "#         # plt.show() \n",
    "#     #print(\"MATRIX\", matrix)\n",
    "#         training_data.append([scaled_image, class_num])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m107"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
